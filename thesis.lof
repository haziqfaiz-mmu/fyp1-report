\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\contentsline {figure}{\numberline {1.1}{\ignorespaces Semantic Segmentation of a Satellite Image}}{2}{figure.1.1}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Object Detection of a Satellite Image}}{3}{figure.1.2}%
\addvspace {10pt}
\contentsline {figure}{\numberline {2.1}{\ignorespaces An Image From Potsdam Dataset}}{12}{figure.2.1}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces An mask From Potsdam Dataset}}{12}{figure.2.2}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces An Image From Vaihingen Dataset}}{13}{figure.2.3}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces An mask From Vaihingen Dataset}}{13}{figure.2.4}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces An Image From LoveDa Dataset}}{14}{figure.2.5}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces An Image From GID-5 Dataset}}{15}{figure.2.6}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces A Mask From GID-5 Dataset}}{16}{figure.2.7}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces An Image From Deep Globe Dataset}}{17}{figure.2.8}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces A Mask From Deep Globe Dataset}}{18}{figure.2.9}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Computing a histogram of oriented gradients for the first patch of an input image.}}{20}{figure.2.10}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces Each circle represents the location and orientation of SIFT keypoints}}{21}{figure.2.11}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces U-Net Architecture}}{27}{figure.2.12}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces Attention U-Net Architecture}}{28}{figure.2.13}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces Multi Attention U-Net Architecture}}{29}{figure.2.14}%
\contentsline {figure}{\numberline {2.15}{\ignorespaces UNetFormer Architecture}}{31}{figure.2.15}%
\contentsline {figure}{\numberline {2.16}{\ignorespaces Global-Local Transformer Block in UNetFormer}}{31}{figure.2.16}%
\contentsline {figure}{\numberline {2.17}{\ignorespaces Feature refinement Head of UNetFormer}}{33}{figure.2.17}%
\contentsline {figure}{\numberline {2.18}{\ignorespaces LANet Architecture}}{34}{figure.2.18}%
\contentsline {figure}{\numberline {2.19}{\ignorespaces Patch Attention Module in LANet}}{35}{figure.2.19}%
\contentsline {figure}{\numberline {2.20}{\ignorespaces Attention Embedding Module in LANet}}{36}{figure.2.20}%
\contentsline {figure}{\numberline {2.21}{\ignorespaces (a) Overall architecture of DC-Swin. (b) Pair of Swin Transformer blocks. (c) Downsample Connection. (d) Large Field Upsample Connection. (e) SSA. (f) SCA}}{36}{figure.2.21}%
\contentsline {figure}{\numberline {2.22}{\ignorespaces Architecture of Bilateral Awareness Network (BANet)}}{38}{figure.2.22}%
\contentsline {figure}{\numberline {2.23}{\ignorespaces Architecture of Adaptive Enhanced Swin Transformer with U-Net (AESwin-UNet)}}{39}{figure.2.23}%
\contentsline {figure}{\numberline {2.24}{\ignorespaces The size records of Vision Transformer in recent years}}{42}{figure.2.24}%
\addvspace {10pt}
\contentsline {figure}{\numberline {3.1}{\ignorespaces Rosenblatt Perceptron}}{44}{figure.3.1}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Encoder-Decoder Architecture}}{47}{figure.3.2}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Attention Mechanism Unit}}{50}{figure.3.3}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Multi-head Attention}}{51}{figure.3.4}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Transformer Architecture}}{52}{figure.3.5}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Sigmoid Function}}{53}{figure.3.6}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces ReLU Function}}{54}{figure.3.7}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces ViT Architecture}}{56}{figure.3.8}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Swin Transformer V1 Architecture}}{57}{figure.3.9}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Cyclic Shifted Windows in Swin Transformer}}{57}{figure.3.10}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Difference Between Swin V1 and Swin V2}}{58}{figure.3.11}%
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
